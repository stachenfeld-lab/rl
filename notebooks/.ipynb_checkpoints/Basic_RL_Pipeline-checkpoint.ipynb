{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ab1a074-c6b8-459f-8327-003cf052fcd4",
   "metadata": {},
   "source": [
    "# Training for Generic RL agents in OpenAI Gym environments\n",
    "#### Stachenfeld lab \n",
    "##### update July 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9cd2e-ea90-42f5-b98e-b2a0d2a2ceb9",
   "metadata": {},
   "source": [
    "## Section 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531aaf63-9175-4b88-95de-1680d843941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## generic imports ##################\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np  # Importing numpy for numerical operations and working with arrays.\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt  # Importing matplotlib for plotting and data visualization.\n",
    "import matplotlib.gridspec as gridspec  # Importing gridspec for creating grid layouts.\n",
    "import matplotlib.patches as mpatches  # Importing patches module for drawing shapes.\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Importing 3D plotting tools.\n",
    "from matplotlib import cm  # Importing cm (colormaps) module.\n",
    "\n",
    "# Open AI gym for the environment\n",
    "import gymnasium as gym\n",
    "\n",
    "# Statistics and mathematical operations\n",
    "import scipy  # Importing scipy for scientific computing.\n",
    "from scipy import stats, integrate  # Importing stats and integrate modules from scipy.\n",
    "from scipy.stats import mode, pearsonr, ttest_rel  # Importing mode, Pearson's correlation, and t-test for related samples.\n",
    "\n",
    "# Other useful libraries\n",
    "from collections import defaultdict  # Importing defaultdict for creating dictionaries with default values.\n",
    "from copy import copy  # Importing copy function for creating shallow copies.\n",
    "import operator  # Importing operator module for standard operators as functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296239bd-ec50-4fe5-918d-9fa596a2dd18",
   "metadata": {},
   "source": [
    "###  environments \n",
    "\n",
    "1. **Initialize Environment**\n",
    "    - Create environment using the provided environment name\n",
    "    - All environments are built with AI Gym\n",
    "    - The import section should have the following structure:  \n",
    "\n",
    "    > ```python\n",
    "    from task_file import Task\n",
    "    task_env = Task(task_params)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46cac65a-0ed3-4013-bd1b-38eeb0119401",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### import environment #####################\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# sanity check the environment \n",
    "def env_preview(env):\n",
    "    env.reset()\n",
    "    for dummy in range(100):\n",
    "        env.render()\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "def show_action_and_env_space(env):\n",
    "    # Action space and environment space\n",
    "    print(\"env.action_space\", env.action_space)\n",
    "    print(\"env.observation_space\", env.observation_space)\n",
    "    print(\"env.observation_space.high\", env.observation_space.high)\n",
    "    print(\"env.observation_space.low\", env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673972ec-df09-44e2-882e-5b362f1372cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### import model ############################\n",
    "\n",
    "from agent_file import Agent  #  replace with the actual agent \n",
    "agent = Agent(task_env, epsilon=0.1, step_size=0.1, discount_factor=0.99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bfe7d-352c-42d9-bab4-cbe2beb96c46",
   "metadata": {},
   "source": [
    "\n",
    "2. **Initialize Results Containers**\n",
    "    - Initialize lists to hold rewards per episode\n",
    "    - Initialize lists to hold steps per episode\n",
    "\n",
    "3. **Training Loop (for each episode)**\n",
    "    - Reset environment and initialize state\n",
    "    - Initialize total_reward and steps counters\n",
    "    - Set done flag to False\n",
    "\n",
    "    4. **Episode Loop (while not done and steps < max_steps_per_episode)**\n",
    "        - Select action using the agent's policy\n",
    "        - Perform action in the environment\n",
    "        - Observe next_state, reward, and done flag\n",
    "        - Update agent with current state, action, reward, and next state\n",
    "        - Update state to next_state\n",
    "        - Accumulate reward to total_reward\n",
    "        - Increment steps counter\n",
    "\n",
    "    5. **End of Episode**\n",
    "        - Append total_reward to rewards_per_episode list\n",
    "        - Append steps to steps_per_episode list\n",
    "        - Print episode summary (optional)\n",
    "\n",
    "6. **Return Results**\n",
    "    - Return rewards_per_episode, steps_per_episode, and final Q-values of the agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20de30-1c49-49cf-a0a1-844b541d56f4",
   "metadata": {},
   "source": [
    "## Section 2: Define Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22616e19-2441-410a-be43-91a571466658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (task_environment, model, algorithm, num_episodes):\n",
    "    #loop over episodes \n",
    "        # observe one state of environment \n",
    "        # pass it to model\n",
    "        # model makes choice via algorithm \n",
    "        # algorithm determines loss \n",
    "        # model update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135383a-a5d7-4f1e-b4c7-9db3345be1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### an example? sepcific to sarsa tryna figure out how to generalize \n",
    "\n",
    "def train_tabular_agent(agent, env_name, num_episodes=1000, max_steps_per_episode=100):\n",
    "    # Initialize the environment\n",
    "    env = gym.make(env_name)\n",
    "    \n",
    "    # Initialize lists to hold results\n",
    "    rewards_per_episode = []\n",
    "    steps_per_episode = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state = agent.initialize_episode(env)\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        done = False\n",
    "\n",
    "        while not done and steps < max_steps_per_episode:\n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward, done, _, _ = env.step(action)\n",
    "            agent.update(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "\n",
    "        rewards_per_episode.append(total_reward)\n",
    "        steps_per_episode.append(steps)\n",
    "        print(f\"Episode {episode + 1}: Total Reward = {total_reward}, Steps = {steps}\")\n",
    "\n",
    "    return rewards_per_episode, steps_per_episode, agent.q_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f08e841-1ad5-4480-ab6a-ed1079d5b80a",
   "metadata": {},
   "source": [
    "## Section 3: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75569f0-b4ee-4181-b0d8-4fe8bf9e64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot something ? maybe loss over time "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
